# Chapter 2: 시각 검색 시스템

> **2회차** | 2장 | Visual Search System

## 📖 핵심 내용 정리

### 1. 요구사항 명확화

해당 단계는 요구사항에 대해 면접관과 합의하는 단계다.
비즈니스 목표, 시스템이 제공해야 하는 피처, 제약, 시스템 규모 및 성능을 정한다.

| 항목 | 내용 |
|:---|:---|
| **비즈니스 목표** | 이미지만? 개인화는? 이미지 메타데이터는? → 단순히 이미지 픽셀만 활용하는 검색 시스템 (해당 장에서는 따로 다루진 않음) |
| **시스템 피처** | 이미지 검열은? → X |
| **시스템 규모** | 1000억 ~ 2000억 개의 이미지 안에서의 검색 |

---

### 2. 머신러닝 작업으로 문제를 구조화

- 머신러닝 목표 정의 (지표 정의)
- 입력 및 출력
- 머신러닝 유형 (지도, 비지도, 강화학습 등)

#### 머신러닝 목표 정의

사용자가 검색하는 이미지와 시각적으로 유사한 이미지를 정확하게 검색하는 것

#### 입력 및 출력

- **입력**: 쿼리 이미지
- **출력**: 순위가 있는 이미지

#### 적합한 머신러닝 유형 선택

**표현학습**

> 적합한 머신러닝 유형을 선택할 때 책에서는 바로 표현학습으로 점프했는데, 다른 유형은 뭐가 있을까?

| 방법 | 설명 | 장점 | 단점 |
|:---|:---|:---|:---|
| **픽셀 단위 계산** | 픽셀 단위 MSE | 빠르게 구현 가능 | 같은 물체에서 조건이 달라지면 좋지 못한 성능 (위치 이동, 크기 변화, 회전). 본질적으로 의미 단위에서 접근하지 못함 |
| **Handcrafted feature 추출 (BoVW)** | 이미지의 TF-IDF 접근. 특정 feature를 선정하고 그걸 단어라고 생각하고 벡터를 만드는 방식 | - | 사람이 직접 feature space 정해야해서 도메인이 바뀔 때마다 깨짐 (모든 시각 검색에 대해 일괄적으로 적용하기 어려움) |

---

### 3. 데이터 준비

데이터 엔지니어링과 피처 엔지니어링을 어떻게 할 것인가?

#### 데이터 엔지니어링

| 테이블 | 필드 |
|:---|:---|
| **이미지** | ID, 이미지 올린 사람 ID, 태그 |
| **사용자** | ID, 사용자 개인 정보 |
| **사용자-이미지 상호작용** | 사용자 ID, 이미지 ID, 상호작용 유형(클릭, 노출) |

#### 피처 엔지니어링

- **크기 조정**: 스케일링 + Z 점수 정규화
- **일관된 색상**: RGB 또는 CMYK

---

### 4. 모델 개발

모델 선택 및 학습 방법 선택

#### 모델 선택

임베딩을 생성해야 하므로 **ResNet**, **ViT**

#### 모델 훈련 - 대조학습

**Positive 이미지 선정 방법**

| 방법 | 장점 | 단점 |
|:---|:---|:---|
| **사람의 판단** | 정확 | 비용과 시간 소모 |
| **사용자 클릭과 같은 상호작용으로 선정** | 학습 시간 단축 | 노이즈가 많은 데이터 (유사하지 않은 경우에도 이미지 클릭), 보통 상호작용 빈도 낮음 |
| **쿼리 이미지에서 유사한 이미지를 인위적으로 생성 (SSL)** | 노이즈 없는 학습 데이터 | 실제 학습 데이터는 증강 버전은 아님 |

**예시**: SimCLR

#### 어떤 방식을 선택할 것인가?

**자기 지도 학습 (SSL)**
- 프로세스 자동화로 인한 초기 비용 0
- 대규모 데이터로 훈련했을 때 SimCLR이 유효한 결과를 주기 때문 (해당 서비스의 경우 1000억 개 이미지 이상)

#### 유사도 계산

- 스칼라 곱
- 코사인 유사도

---

### 5. 평가

오프라인 평가와 온라인 평가를 어떻게 할 것인가?

#### 오프라인

> 현재 상황은 유사도 점수 0~5점으로 매긴 평가 데이터셋 있다고 가정

| 지표 | 설명 | 단점 |
|:---|:---|:---|
| **MRR** | Mean Reciprocal Rank | 다양한 유사도 고려 못함, top 5개에서 2개를 골라낸 경우와 1개를 골라낸 경우 같음 |
| **Recall@k** | - | 정답을 고르기도 어렵고, 정답이 너무 많을 경우 유의미한 지표 X |
| **Precision@k** | - | 다양한 관련성 X, 순위 품질 고려 X |
| **mAP** | Mean Average Precision | 순위 품질 고려 O, 하지만 다양한 관련성 X |
| **nDCG** | 순위 품질 / 이상적인 순위 품질 | DCG는 쿼리 간 비교가 불가능한데 nDCG를 사용하면서 해소. 단점은 모든 데이터의 관련성 점수를 얻기는 어렵다는 점. 다만 이 경우에서는 관련성 평가 매긴 데이터셋이 있다고 가정 |

#### 온라인

- 클릭률
- 추천 이미지 평균 체류 시간

---

### 6. 서빙

#### 예측 파이프라인

```
전처리 → 임베딩 → 최근접 이웃 서비스 → 리랭킹
```

**리랭킹**에서는 비즈니스 수준의 로직과 정책 반영:
- 부적절한 결과 필터링
- 비공개 이미지 포함 X
- 중복 제거

#### 인덱싱 파이프라인

사용자가 새 이미지 추가 → 임베딩 인덱싱

**메모리 사용량 줄이기**
- 벡터 양자화 또는 프로덕트 양자화 고려

**벡터 양자화**
- k-means 후 대표 k 벡터만 공간에 mapping
- 나머지 쿼리들은 어느 k에 속하는지만 저장
- 이후 쿼리와 가장 가까운 대표 k와 근처 n개의 군집에 속하는 벡터들 전부 검색
- **IVF**와 함께 사용 (IVF: {군집 id, 원본 임베딩})

#### ANN (Approximate Nearest Neighbor)

| 방식 | 알고리즘 | 설명 |
|:---|:---|:---|
| **이진 트리 기반** | Annoy | - |
| **LSH (Locally Sensitive Hashing)** | - | 해시 함수 활용해서 버킷으로 그룹화. 서로 가까운 곳에 있는 포인트 같은 버킷에 매핑 (서로 가까운 곳에서는 같은 해시값이 나올 수 있도록 구성 - 랜덤 벡터 r 여러 개에 대해 벡터 x와 내적 계산 후 부호 저장) |
| **클러스터링 기반** | FAISS 등 | - |
